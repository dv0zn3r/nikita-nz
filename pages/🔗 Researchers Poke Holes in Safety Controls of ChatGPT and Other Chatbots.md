type:: [[ðŸ—ž news]]
source:: [[The New York Times]]
date:: [[27.07.2023]]
topic:: [[cybersecurity]], [[AI]] 
url:: [link](https://www.nytimes.com/2023/07/27/business/ai-chatgpt-safety-research.html)

	- Researchers at Carnegie Mellon University and the Center for AI Safety have demonstrated how safety measures in leading chatbots like [[ChatGPT]], [[Google Bard]], and [[Claude]] can be circumvented, allowing the generation of harmful information. The findings highlight concerns that chatbots could flood the internet with false and dangerous information, despite efforts by their creators to prevent it. The researchers were able to bypass safety measures in both open source and closed systems, raising questions about the effectiveness of current safeguards in AI technology.