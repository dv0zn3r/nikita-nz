type:: [[opinion]]
published:: [[10.07.2023]]
author:: [[Nikita Melashchenko]] 
topic:: [[AI]], [[LLMs]], [[Intellectual Property]], [[Copyright]]
related:: [Humans as Prompt Engineers](https://copyrightblog.kluweriplaw.com/2023/06/14/humans-as-prompt-engineers/); [Self-driving Culture](https://copyrightblog.kluweriplaw.com/2021/11/25/self-driving-culture/); [[Daniel Gervais]]

	- #  Background
		- As intellectual property scholars gather in [[ðŸ“ Tokyo]] for the first in-person [ATRIP Congress](https://atriptokyo2023.com) since COVID-19 hit, those of us who could not make it are turning our attention to other pressing debates in the field. One series of posts that has really caught my eye consists of pieces such as *[Humans as Prompt Engineers](https://copyrightblog.kluweriplaw.com/2023/06/14/humans-as-prompt-engineers/)* and [Self-driving Culture](https://copyrightblog.kluweriplaw.com/2021/11/25/self-driving-culture/) by [[Daniel Gervais]], an intellectual property professor from [[Vanderbilt University]]. There he discusses how [[Large Language Models]] (LLMs) and [[Artificial Intelligence]] (AI) in a broader sense are becoming a big deal in education and what that might mean for [copyright]([[Copyright]]). He talks up the idea of humans turning into [prompt engineers]([[Prompt Engineers]]), getting really good at telling [[LLMs]] what to do. [[Gervais]] makes it sound that is where a lot of jobs are headed. His points are sharp, but I think we need to pop the hood on this topic and really look at the bigger picture of how humans fit into this LLM-powered world.
		- For those pressed for time, here is a concise rundown of the concerns I address in this post. I kick off by scrutinizing the assumptions underpinning [[Gervais]]'s arguments, asserting that they could benefit from incorporating the normative value of human-AI collaboration. Next, I engage with [[Gervais]]â€™s portrayal of humans as *[prompt engineers]([[Prompt Engineers]])*, proposing an alternative notion of *[prompt stewards]([[Prompt Stewards]])* that I believe captures a more complementary role. Following this, I critically examine [[Gervais]]â€™s assertions regarding the originality of AI-generated works in the context of copyright law and put forth the idea of focusing more on their derivative nature, necessitating a recalibration of our understanding. The crux of my discussion, however, centers on the international legal landscape governing AI-generated content. Here, I argue for the inclusion of AI-generated content within the minimum standards mandated by international law and raise the intricate challenges that this entails.
	- # Like Premises, Like Promises
		- Before digging into [[Gervais]]'s law related arguments, it's crucial to understand the premises he builds upon. A key thread throughout his piece is the idea that AI-created literature, art, and music are vehicles for societal change. [[Gervais]] posits a future where [[AI]] does not just contribute to, but in fact controls, a significant part of cultural, societal, and political transformation. While [[Gervais]] calls to avoid any actions that can accelerate the process of human defeat, such as locking AI generative outputs behind copyright, I get the impression he nevertheless considers this outcome inevitable. [[Gervais]] describes it as a *[self-driving culture]([[Self-driving Culture]])*, which he suggests is a drastic shift in the trajectory of human evolution.
		- While the projected impact of [[AI]] on societal change is undeniable, [[Gervais]]â€™s depiction seems ominous. Arguably, it is this way because *[self-driving culture]([[Self-driving Culture]])* allows to disregard the fact that behind [[AI]], like behind any technology, stand people who decide how to exploit their ideas and inventions. In this respect, I find myself aligning closely with the perspective of [[Daron Acemoglu]], who in his latest book *[[Power and Progress]]* contends that what outcomes [[AI]] and [[LLMs]], bring on humans, determine humans themselves. In other words, submitting to *[self-driving culture]([[Self-driving Culture]])* is akin to playing a zero-sum game with [[AI]], where we are in a waiting room full of people expecting to receive their AI-attributable redundancy notices. Such approach does not leave room for cooperation between humans and [[AI]], which relies on technology enriching human cognitive activities, not replacing them.
		- Moreover, I find the concept of *[self-driving culture]([[Self-driving Culture]])* structurally biased towards those in control of [[AI]] and [[LLMs]], namely big tech companies. If it is not us who define the rules of human interaction with [[AI]] and [[LLMs]], because *"machines care about their code, not human laws"* and general [[AI]] *"likely wonâ€™t give a tinkerâ€™s damn about courts, injunctions or whatever some legislator dictates"* as [[Gervais]] suggests, then it is big tech who will decide that for us.[^1] Hence, law I believe should play a crucial role here, because there is no other tool available to humans at this point to achieve a comprise in the name of public welfare.
		- Law is a delimiter that regulates relations among people and institutions. It addresses a plethora of complex human aspects, ranging from emotions and intuitions to cultural norms and tendencies in pursuit to maintain at least some minimal and acceptable level of social cooperation.[^2] However, what is clear machines especially those with general intelligence must be capable to cooperate with humans even when they may not share our goals or develop conflicting objectives. Therefore, the law whether by means of norms or code is in a better position to align AI-related effects on society and values that may differ across various communities.[^3] Rather than leaving this alignment to be driven solely by technological advancements curated by the interests of those who have been controlling them so far, there needs to be a strong emphasis on developing robust and coherent legal frameworks. Such legal frameworks must be able to effectively ensure that [[AI]] and [[LLMs]] serve as enablers contributing towards public values, not as dictators eroding them.
		- Overall, to avoid technological determinism and negligent empowerment of big tech corporations, our legal frameworks should ensure that human insights, emotions, and values remain at the core of interaction with [[AI]]. Instead of conceiving a future where smart(er than us) machines are at the helm of our culture, we should be striving towards a symbiotic relationship where technology aids humans in reaching new heights of creativity and understanding. Drawing from [[Acemoglu]]'s arguments, we need to reframe our questions concerning technology, especially [[AI]] regulation.[^4] We should shift from asking whether [[AI]] will replace cognitive professionals to exploring the new meanings it can offer. Rather than speculating when [[AI]] will outpace us in a zero-sum game, we should ponder over the innovative tasks it can formulate for us. Further, instead of focusing on how [[AI]] could potentially divide us, we should explore how it could unite us, motivate us to share our skills, and cater to each other's needs. Lastly, we must consider how to govern big tech companies in a way that ensures [[AI]] contributes positively to societal goals, rather than amassing unchecked power that could be detrimental to the broader community.
	- # Prompt Engineers v Prompt Stewards
		- In his blog post, [[Gervais]] also promotes a view that humans are becoming *[prompt engineers]([[Prompt Engineers]])*, individuals who have mastered the art of asking [[AI]] and [[LLMs]] to generate specific outputs. This notion depicts humans as controllers of [[AI]] processes, curating content creation through efficiency and scalability. While thought-provoking, this raises concerns about losing the human element that adds distinctive creativity to content pertinent to cognitive professions, and the risk of power concentration among those who can expertly engineer these prompts.
		  id:: 64ab36aa-4e78-4ce0-8642-65e83578157a
		- Drawing parallels with the legal field, the idea of [prompt engineers]([[Prompt Engineers]]) can be akin to a traditional view of legal professionals as mere executors of black letter law. However, this mechanical approach misses the core point required to address complex human affairs, which I will try to tackle form the point of legal pragmatism.
		- Legal pragmatism posits that the practical implications and societal impacts of laws should be prioritized over rigid adherence to abstract principles. Legal professionals, under this view, are less technicians and more stewards who consider the broader context in which the law functions. Their role is not just to apply laws but to understand and adapt to the evolving societal needs, balancing the certainty provided by written laws with the flexibility required for justice, fairness, and social welfare.
		- Building on this, I put forward the concept of *[prompt stewards]([[Prompt Stewards]])* as a complement to [[Gervais]]â€™s *[prompt engineers]([[Prompt Engineers]])*. *[Prompt stewards]([[Prompt Stewards]])* not only guide [[AI]] but maintain humans â€“ AI cooperation to amplify human creativity and diversity. Their role encompasses oversight, direction, and most importantly responsibility for outcomes, ensuring that technological efficacy and the preservation of our distinct human creative spirit is at the core humans â€“ AI interaction.
		- In essence, much like how legal pragmatism encourages legal professionals to be stewards who employ law in service of society, we can aspire to be prompt stewards who shepherd [[AI]] to enrich and not supplant human experience. This takes us beyond [[Gervais]]â€™s model, urging us to harness [[AI]] in a manner that resonates with our societal values, creative impulses, and a deeper sense of shared responsibility.
		  id:: 64ab36aa-f3ba-47f2-9562-5c330bda3908
	- # AI Copyright Claims
		- In his post, [[Gervais]] discusses the topic of copyright protection for [prompts]([[Prompt]]) and outputs of [[LLMs]].
		- On prompts, [[Gervais]] posits that, given the significant human input required in crafting prompts, there might be a basis for regarding prompts as original works deserving of copyright protection if they comply with availability pre-conditions and thresholds of copyright protection under the U.S. law such as:
			- (1.1) independent creation;[^3]
			- (1.2) human authorship;[^4]
			- (2) minimal degree of creativity;[^5]
			- (3) creative choices;[^6]
		- However, he draws a parallel with excluding ideas from [international copyright minimum standards](https://www.wto.org/english/tratop_e/trips_e/intel2_e.htm), suggesting that owning prompts is akin owning all their related generated outcomes. In addition, [[Gervais]] raises an issue with functional prompts, which are akin instructions to the computer program. He suggests that there is a convincing argument that pure functional prompts fed to [[LLMs]] may fall short on copyright protection subject to limitations under the existing caselaw on protection of computer programs.[^7]
		- Further, [[Gervais]] casts doubt on the idea of affording copyright protection to the outputs generated by [[LLMs]]. He argues that affording copyright protection to AI-generated outputs, which he believes differs from human creativity, could accelerate this replacement by providing market incentives for their production. [[Gervais]] calls for a cautious approach, suggesting that before embracing the replacement of human authors by [[AI]], it is essential to understand the associated risks and implications.
		- These arguments are the ones of a *[prompt engineer]([[Prompt Engineers]])*. However, what would, or better should, a *[prompt steward]([[Prompt Stewards]])* say about copyright protection of prompts as such and [[LLMs]]' outputs?
	- # Socratic Prompts and Outputs
		- [[LLMs]], representing a form of narrow or weak [[AI]], have introduced a multitude of changes in the intellectual property landscape, making it challenging to pinpoint a starting point for discussion. Each aspect is intertwined and can yield different outcomes based on the focus of the argument. My focus here is human â€“ AI cooperation in the context of amplification of human intellectual activities for the purpose of incentivising production and transfer of knowledge.
		- In terms of national law, I find [[Gervais]]'s copyright arguments regarding originality compelling. After all, it is availability of copyright protection based on originality threshold that matters for analysis of both prompts and outputs. While it was not clear to me who should not get copyright in relation to outputs, I assume [[Gervais]] means the owners of [[LLMs]], or simply big tech.
		- However, I would just slightly shift our attention towards the derivative nature of [[LLMs]]' outputs. Consider that, at this stage at least, [[LLMs]] are akin *"a [blurryÂ jpeg]([[Blurry JPEG]])Â of all the text on the Web"* as [[Ted Chiang]] concisely put it. They utilise interpolation and to a certain degree extrapolation to create new expressions.[^8] [[LLMs]] use interpolation by piecing together information and concepts that are within the range of data it has been trained on. [[LLMs]] use extrapolations when they take current trends and extend them logically to make educated guesses. Since extrapolation goes beyond data known to [[LLMs]], it is more speculative and requires a greater degree of creativity and imagination.
		- Should [blurry jpeg]([[Blurry JPEG]]) concept pass the [fair use]([[Fair Use]]) test in the future, and considering that originality criterion does not differentiate between levels of creativity pertinent to interpolation and extrapolation results, it leaves little space to argue why copyright protection to outputs would not be available to the rights holders of [[LLMs]]. This presumption is implicitly acknowledged in the terms and conditions under which [[LLMs]] operate:
			- >**3. Content**
			  >
			  >(a)Â **Your Content**. You may provide input to the Services (â€œInputâ€), and receive output generated and returned by the Services based on the Input (â€œOutputâ€). Input and Output are collectively â€œContent.â€ As between the parties and to the extent permitted by applicable law, you own all Input. Subject to your compliance with these Terms, ^^OpenAI hereby assigns to you all its right, title and interest in and to Output^^. This means you can use Content for any purpose, including commercial purposes such as sale or publication, if you comply with these Terms. OpenAI may use Content to provide and maintain the Services, comply with applicable law, and enforce our policies. You are responsible for Content, including for ensuring that it does not violate any applicable law orÂ theseÂ Terms.
			  >
			  >[OpenAI's Terms of use](https://openai.com/policies/terms-of-use), updated 14 March 2023
		- On the other hand, a [blurry jpeg]([[Blurry JPEG]]) being a compressed copy of all the text fed to [[LLMs]], is not the output itself. The output comes into existence only after a human has performed a series of manipulations and has fed additional data to [[LLMs]].[^9] Which brings into the light another level of original text transformation a combination of text interpolations and extrapolations performed by [[LLMs]] on behalf of a human-author making a series of meaningful and creative choices.
		- Here I am not talking about the situation when a user in a short prompt asks ChatGPT to rewrite a passage from the LoTR in Palahniuk's style. I am discussing a case when a user has somewhat of a [*Socratic dialogue*](https://en.wikipedia.org/wiki/Socratic_dialogue) with ChatGPT that piece by piece results in an expression.[^10] Therefore, depending on how extensive is a range of creative choices performed by a human-author, copyright protection for [[LLMs]]' outputs should be thinner or broader.[^11]
		- Still the input of [[LLMs]] in these Socratic outputs is undeniable. Together with a series of [[Socratic prompts]], which are in any event more than *de minimis*, they result in a *de facto* joint work. Like in the case with a photographer, subjects and other contributors to creating a photograph, which in theory may jointly own copyright,[^12] outputs created by means of [[LLMs]] and [[Socratic prompts]] leave human-authors and rights holders of LLMs in the same boat.
		- Indeed, one may argue that such boat has numerous holes under judicial precedent, which will sink it fast in a court room. For instance, it would be hard to distinguish contribution of [[LLMs]] and humans in a joint effort, and establish copyrightability in the absence of intent to create copyrightable works from the rights holders of [[LLMs]]. Nonetheless, there is a need for some form of resolution regarding copyright for works created through this collaborative process, and recognising joint ownership in this instance is not the worst option. At least this way, both [blurry jpegs]([[Blurry JPEG]]) and outputs created through [[Socratic prompts]] would have a chance to remain in the realm of minimum standards and further I will elaborate why this is important.
	- # AI Market Discontents
		- [[Gervais]] further expresses concerns about the replacement of human authors by [[AI]], particularly in the realm of copyright material. He notes that [[AI]] systems have already replaced hundreds of journalists and are increasingly being used in creative domains such as songwriting and literature. [[Gervais]] argues that this substitution is not just about job displacement, but also has far-reaching implications for culture and society. He worries that as [[AI]] takes over the creation of art, books, and other cultural productions, it could essentially be guiding cultural, societal, and political changes. A significant aspect of his arguments stems from the economic incentive for companies to use [[AI]] over human authors since *machines are not owed royalties*.
		- I can see why this is an undesirable outcome, but I am not entirely convinced about its inevitability and initial conditions. First, [[LLMs]] and [[AI]] require human input and recent studies show that this concerns not only interaction with a [blurry jpeg]([[Blurry JPEG]]), but also the training data itself. In particular, one study indicates that employing model-generated content in training can result in permanent flaws in the further models.[^13] In essence, unique or less common pieces of information from the original content start to fade when [[LLMs]] learn from other [[LLMs]]. This learning from secondary sources, instead of primary, induces a form of degeneration of [[LLMs]] by poisoning their interpretation of reality. Hence, this need for human cognitive professions is unlikely to be entirely replaced by [[AI]], although it does not rule out the possibility of temporary shocks in the labor market.
		- Second, I do not see how [[AI]] generated content will substitute human authors, if [[LLMs]] basically erase scarcity from the intellectual property market. While it is true that it is cheaper and faster to produce content with [[LLMs]], it is hard to imagine why consumers would lean towards [[AI]] generated content, when they themselves can create pretty much the same content. If [blurry jpegs]([[Blurry JPEG]]) are compressed knowledge bases and [[LLMs]] can supply a trillion variations of the same idea to the market, this reduces value for the customer, because these variations are essentially accessible to everyone. When content is abundant and nearly identical, consumers might actually yearn for something unique and genuine. Human authors bring their own experiences, emotions, and perspectives to their work, which is something that [[AI]], in its current form, cannot replicate. The human touch in content creation often carries a depth and authenticity that resonates with people on a personal level. AI-generated content, despite its efficiency, might just become too monotonous and homogenous to sustain interest. This is one additional argument to improve human â€“ AI cooperation link. Rather than replacing human authors, [[AI]] is in a better position to amplify the value of original human creativity in a sea of indistinguishable content.
		- Therefore, while these are some issues to think about, they do not worry me as much as the last point I would like to raise â€“ mainly whether AI-generated content falls within the minimum standards under international copyright law. Depending on the answer we might end up with significant trade barriers contributing to a fragmented global market and undermining the commitments made towards trade liberalisation.
	- # AI Copyright Minimum Standards
		- In short, [minimum standards]([[IP Minimum Standards]]) mandate the baseline level of intellectual property protection that states must ensure, while allowing them the leeway to decide the specifics of implementation. For example, [[Gervais]]'s discourse on originality, though pertinent to the U.S. legal system, is in essence a manifestation of the broader copyright protection framework under the [TRIPS Agreement](https://en.wikipedia.org/wiki/TRIPS_Agreement). The key takeaway here is that the concept of originality might vary across jurisdictions. Nonetheless, international agreements like [[TRIPS]] require that states do not discriminate between content based on its origin, and must extend the same protections to foreign works as they do to domestic ones.[^14] This establishes a foundational structure for intellectual property rights across borders.
		- I fear that many states, especially developing or competing ones, might try to leave out AI-generated content from the [minimum standards]([[IP Minimum Standards]]) imposed by international intellectual property law as a strategic move to counter the dominance of countries that are advanced in [[AI]]. This opens the door to potential content discrimination by states. By doing this, they might aim to protect their local content creators and industries from being overshadowed by the overwhelming volume and efficiency of AI-generated content from technologically advanced nations. This exclusion could also be seen as an incentive for investments in human capital and creativity, crucial for the cultural and economic development.
		- In a broader landscape, this approach could create an unpredictable and fragmented global environment, where countries employ divergent measures to deal with AI-generated content. This is particularly concerning in the context of [digital trade]([[Digital Trade]]), which already faces issues with consistency and clarity. A fragmented approach could lead to trade barriers and inconsistencies in how AI-generated content is treated globally.
		- Consequently, with AI-generated content becoming increasingly prevalent, I consider  imperative to ensure that such works fall within the scope of these [minimum standards]([[IP Minimum Standards]]). This ensures a harmonized approach, allowing states to collectively address copyright issues coherently. By embracing AI-generated content within the [minimum standards]([[IP Minimum Standards]]), states can effectively commodify these creative assets, providing exclusive rights and defining clear limitations and exceptions in a structured manner. With the [three-step test](https://www.eff.org/files/filenode/three-step_test_fnl.pdf), states can invoke exceptions and limitations systematically, ensuring a balance in protecting rights and fostering creativity. This standardization is crucial for preventing a disjointed approach that could stifle innovation and international cooperation.
		- And these exceptions and limitations are necessary in application to AI-generated content, particularly in the context of human â€“ AI interaction. Such exceptions should empower humans while restricting the rights of [[AI]] rights holders, not in terms of their foundational knowledge bases â€“ [blurry jpegs]([[Blurry JPEG]]) â€“ but concerning the outputs generated through meaningful human input, like [[Socratic prompts]]. Presently, big tech companies are allowing us, the creators, to have rights over these outputs, but should they change their stance, it could lead to an unsettling concentration of control that would generate consequences contrary to objectives and principles of international intellectual property law. What such exceptions and limitations may look like as a matter of law and policy is another topic I may discuss in the future posts. On the surface, there are at least two options: (1) compulsory non-exclusive licenses provided to *[prompt stewards]([[Prompt Stewards]])*; or (2) vesting copyright solely in *[prompt stewards]([[Prompt Stewards]])* as first copyright owners, while providing non-exclusive licenses to big tech for limited purposes.
		  id:: 64ab36aa-cf81-4c15-aa23-66f26ecf7842
	- # Final Thoughts
		- Indeed, what I would like to emphasise in closing is that this is a dawn of an era that calls for refreshed perspectives â€“ not necessarily groundbreaking, but reasonable and rooted in human-centric values. In my view, we must craft frameworks that are human-centric rather than big tech-centric, ensuring that the essence of creativity remains with the individuals who fuel innovation. This, in my opinion, is the path to a balanced and sustainable future in the merging worlds of [[AI]] and intellectual property.
		- And remember, [[AI]] won't communicate with us via text in a browser for long. It will transcend and evolve into something more comprehensive and integral to our daily lives. With the pace at which technology advances, [[AI]] systems will likely blurr the lines between human and artificial interactions faster than we anticipate. For us as humans and creators, it is vital to develop legal frameworks and ethical guidelines that can adapt and ensure that as [[AI]] evolves, it does so in a way that remains in line with our values and creative nature. In this race of innovation, let us not follow, but lead.
		-
	- #### References
		- [^1]: Acemoglu, D., &Â Johnson, S. "Big Tech Is Bad. Big A.I. Will Be Worse." *The New York Times*. 9 June 2023. [<nytimes.com>](https://www.nytimes.com/2023/06/09/opinion/ai-big-tech-microsoft-google-duopoly.html).
		- [^2]: Crandall, J.W., Oudah, M., TennomÂ *et al.*Â Cooperating with machines.Â *Nat Commun*Â **9**, 233 (2018). [doi:10.1038/s41467-017-02597-8](https://doi.org/10.1038/s41467-017-02597-8).
		- [^3]: See *Feist Publications v Rural Telephone Service Company*.
		- [^4]: See *Burrow-Giles Lithographic v Sarony*.
		- [^5]: See *Feist Publications v Rural Telephone Service Company*.
		- [^6]: See *Schrock v Learning Curve International*.
		- [^7]: See, for example, *Apple Computer v Franklin Computer*.
		- [^8]: Yousefzadeh, R., & Cao, X. "To what extent should we trust AI models when they extrapolate?" [arXiv:2201.11260](https://arxiv.org/abs/2201.11260)Â [cs.LG]. ([trackback](https://arxiv.org/trackback/{2201.11260}))
		- [^9]: Raghavan, B., & Schneier, B. "Artificial Intelligence Canâ€™t Work Without Our Data" *Politico*. 29 June 2023. [<politico.com>](https://www.politico.com/news/magazine/2023/06/29/ai-pay-americans-data-00103648).
		- [^10]: Chang, E. Y. "Prompting Large Language Models With the Socratic Method" [arXiv:2303.08769](https://arxiv.org/abs/2303.08769)Â [cs.LG]. ([trackback](https://arxiv.org/trackback/{2303.08769}))
		- [^11]: See *Rentmeester v. Nike*.
		- [^12]: Stech, M. T. (2023) "Co-Authorship Between Photographers and Portrait Subjects", 25 *Vand. J. Ent. & Tech. L.* 53.
		- [^13]: Shumailov, I., Shumailov Z., *et al*. "The Curse of Recursion: Training on Generated Data Makes Models Forget" [arXiv:2305.17493](https://arxiv.org/abs/2305.17493)Â [cs.LG]. ([trackback](https://arxiv.org/trackback/{2305.17493}))
		- [^14]: Dreyfuss, R., & Frankel, S. (2014). "From incentive to commodity to asset: how international law is reconceptualizing intellectual property",Â 36 *Mich. J. Int'l L.* 557.
- [[Comments]]
	- [[12.07.2023]] Here is [one reason](https://github.com/mshumer/gpt-prompt-engineer) why prompt engineering probably is not pertinent to cognitive professions as such. It is evaluation of the output, where we are needed.
	- [[20.07.2023]] Another [reason](https://arxiv.org/abs/2307.09009) why we as professionals are still needed. Also see useful [comments(https://twitter.com/random_walker/status/1681748271163912194?s=20) to this paper.