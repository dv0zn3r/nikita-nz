type:: [[üìù article]]
author:: [Lingjiao Chen](https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+L),¬†[Matei Zaharia](https://arxiv.org/search/cs?searchtype=author&query=Zaharia%2C+M),¬†[James Zou](https://arxiv.org/search/cs?searchtype=author&query=Zou%2C+J)
topic:: [[AI]]
category:: [[computer science]]
source:: [[arxiv]]
url:: [link](https://arxiv.org/abs/2307.09009)

	- This study evaluates the performance of two widely used language models, GPT-3.5 and GPT-4, in solving math problems, answering sensitive questions, generating code, and visual reasoning. The results show that the behavior and performance of these models can vary significantly over time. For instance, GPT-4 performed well in identifying prime numbers in March but poorly in June, while GPT-3.5 improved in this task from March to June. Additionally, both models had reduced willingness to answer sensitive questions in June and more formatting mistakes in code generation. These findings highlight the importance of continually monitoring and assessing the quality of language models.